# Audio Pipeline - LiveKit + ElevenLabs Realtime STT

Real-time audio pipeline for interview transcription with speaker separation via LiveKit and ElevenLabs.

## ğŸ¯ Features

- âœ… LiveKit connection as bot
- âœ… Audio track capture from each participant
- âœ… Audio conversion WebRTC â†’ PCM 16kHz mono
- âœ… ElevenLabs Realtime STT connection per speaker
- âœ… Real-time audio streaming
- âœ… Transcripts with speaker labels (recruiter/candidate)
- âœ… Target latency < 500ms
- âœ… Error handling and automatic reconnection

## ğŸ“¦ Installation

```bash
# Install dependencies
pip install -r requirements.txt
```

## ğŸ”§ Configuration

Create a `.env` file at the project root:

```bash
# LiveKit Configuration
LIVEKIT_URL=wss://your-livekit-server.com
LIVEKIT_ROOM=interview-room
LIVEKIT_TOKEN=your_jwt_token

# ElevenLabs Configuration
ELEVENLABS_API_KEY=your_elevenlabs_api_key
```

### Generating a LiveKit Token

To generate a LiveKit JWT token:

```python
from livekit import api

token = api.AccessToken(api_key, api_secret) \
    .with_identity("bot") \
    .with_name("Transcription Bot") \
    .with_grants(api.VideoGrants(
        room_join=True,
        room="interview-room",
    )).to_jwt()
```

## ğŸš€ Usage

### Basic Usage

```python
import asyncio
from audio_pipeline import AudioPipeline

async def main():
    pipeline = AudioPipeline(
        livekit_url="wss://your-server.com",
        livekit_room="interview-room",
        livekit_token="your_token",
        elevenlabs_api_key="your_api_key",
        language="en"  # or "fr" for French
    )

    async for transcript in pipeline.start_transcription():
        print(f"[{transcript.speaker}] {transcript.text}")

asyncio.run(main())
```

### Usage with Provided Example

```bash
python example_usage.py
```

## ğŸ“Š Project Structure

```
audio_pipeline/
â”œâ”€â”€ __init__.py           # Public exports
â”œâ”€â”€ models.py             # Transcript dataclass
â”œâ”€â”€ livekit_handler.py    # LiveKit management
â”œâ”€â”€ elevenlabs_stt.py     # ElevenLabs WebSocket client
â”œâ”€â”€ audio_converter.py    # Audio conversion
â”œâ”€â”€ pipeline.py           # Main pipeline
â””â”€â”€ error_handling.py     # Error handling
```

## ğŸ¤ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LiveKit    â”‚
â”‚   Room      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€ Participant 1 (Recruiter)
       â”‚    â””â”€â”€â”€ Audio Track
       â”‚         â”‚
       â”‚         â”œâ”€â–º AudioConverter (PCM 16kHz)
       â”‚         â”‚
       â”‚         â””â”€â–º ElevenLabs STT WebSocket
       â”‚              â””â”€â–º Transcripts (speaker="recruiter")
       â”‚
       â””â”€â”€â”€ Participant 2 (Candidate)
            â””â”€â”€â”€ Audio Track
                 â”‚
                 â”œâ”€â–º AudioConverter (PCM 16kHz)
                 â”‚
                 â””â”€â–º ElevenLabs STT WebSocket
                      â””â”€â–º Transcripts (speaker="candidate")
```

## ğŸ“ API Reference

### Transcript

```python
@dataclass
class Transcript:
    text: str              # Transcribed text
    speaker: str           # "recruiter" or "candidate"
    start_ms: int | None   # Start timestamp (ms)
    end_ms: int | None     # End timestamp (ms)
    is_final: bool         # True if final transcription
```

### AudioPipeline

```python
class AudioPipeline:
    async def start_transcription(
        self,
        audio_stream=None
    ) -> AsyncIterator[Transcript]:
        """
        Start real-time transcription

        Yields:
            Transcript: Transcript objects with speaker labels
        """
```

## âš™ï¸ Advanced Configuration

### Custom Identities

```python
pipeline = AudioPipeline(
    ...,
    recruiter_identity="john_interviewer",
    candidate_identity="jane_candidate"
)
```

### Language

```python
pipeline = AudioPipeline(
    ...,
    language="fr"  # French
)
```

## ğŸ› Debug and Logs

To enable detailed logs:

```python
import logging

logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
```

## ğŸ” Troubleshooting

### LiveKit Connection Error

- Verify that the LiveKit URL is correct (wss://)
- Verify that the JWT token is valid and not expired
- Verify that the room exists

### ElevenLabs Error

- Verify that the API key is valid
- Verify that the quota is not exceeded
- Verify the WebSocket connection (firewall, proxy)

### No Transcripts

- Verify that participants have active audio tracks
- Verify that the microphone is authorized
- Check the logs to see if audio is being received

## ğŸ“Š Performance

- **Target latency**: < 500ms
- **Audio format**: PCM 16kHz mono 16-bit
- **Audio chunks**: 100ms (configurable)
- **Connections**: 1 ElevenLabs WebSocket per speaker

## ğŸ” Security

- Never commit `.env` files
- Use JWT tokens with short expiration
- Regular rotation of API keys
- Validation of participant identities

## ğŸš§ Current Limitations

- Maximum 2 participants (recruiter + candidate)
- No hot-swapping of participants
- No fallback if ElevenLabs is down
- No transcript caching

## ğŸ”® Future Improvements

- [ ] Support for more than 2 participants
- [ ] Fallback to Deepgram/Whisper if ElevenLabs fails
- [ ] Transcript caching and persistence
- [ ] Automatic language detection
- [ ] Audio quality metrics
- [ ] Real-time dashboard

## ğŸ“„ License

MIT

## ğŸ¤ Contributing

Contributions are welcome! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## ğŸ“§ Support

For any questions: [your-email]
